---
output: 
  github_document:
    toc: false
    fig_width: 10.08
    fig_height: 6
tags: [r, complexity]
vignette: >
  %\VignetteIndexEntry{README}
  \usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
bibliography: bibliography.bib
csl: utils/apa.csl
---

```{r, echo = FALSE, warning=FALSE, message=FALSE}
# options and parameters
options(digits=3)

knitr::opts_chunk$set(
  collapse = TRUE,
  dpi=450,
  fig.path = "../../studies/complexity_benchmark/figures/"
)

# Setup python - you need to change the path to your python distribution
# library(reticulate)
# reticulate::py_discover_config()
# use_python("C:/Program Files/Python39/python.exe")
# py_run_string("import sys")
# py_run_string("sys.path.append('C:/Dropbox/RealityBendingLab/Pyllusion/')")
# py_run_string("sys.path.append('C:/Dropbox/RECHERCHE/N/NeuroKit/')")
# py_run_string("sys.path.append('C:/Dropbox/RECHERCHE/N/mne-python/')")
```




# Benchmarking and Analysis of Complexity Measures

*This study can be referenced by* [*citing the package*](https://github.com/neuropsychology/NeuroKit#citation) [@Makowski2021neurokit].

**We'd like to improve this study, but unfortunately we currently don't have the time. If you want to help to make it happen, please contact us!**

## Introduction

The goal for NeuroKit is to provide the most comprehensive, accurate and fastest base Python implementations of complexity indices (fractal dimension, entropy, etc.).

## Computation Time

### Make data

```{python, eval=FALSE}
# See make_data.py
```

### Benchmark

#### Average Duration

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(easystats)

df <- read.csv("data_ComputationTime.csv") 

order <- df |> 
  group_by(Method) |> 
  summarize(Duration = median(Duration)) |> 
  arrange(Duration) |> 
  mutate(Method = factor(Method, levels = Method))

df <- mutate(df, Method = fct_relevel(Method, as.character(order$Method)))

dfsummary <- df |>
  group_by(Method, Length) |>
  summarize(Duration = median(Duration))


ggplot(dfsummary, aes(x = Method, y = Duration)) + 
  geom_hline(yintercept = c(0.001, 0.01, 0.1, 1), linetype = "dotted") +
  geom_line(aes(alpha = Length, group = Length)) +
  geom_point(aes(color = Length)) + 
  theme_modern() +
  scale_y_log10(breaks = c(0.001, 0.01, 0.1, 1)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  guides(alpha = "none") +
  labs(y = "Time to compute", x = NULL, color = "Signal length")
```

#### Sensitivity to signal length

```{r message=FALSE, warning=FALSE}
df |> 
  ggplot(aes(x = as.factor(Length), y = Duration)) +
  geom_hline(yintercept = c(0.01), linetype = "dotted") +
  geom_line(data=dfsummary, aes(group = 1)) +
  geom_violin(aes(fill = Length)) +
  facet_wrap(~Method) +
  scale_y_log10() +
  scale_fill_viridis_c(guide = "none") +
  theme_modern() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```

## Structure

### Correlation

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(easystats)

df <- read.csv("data_Correlations.csv") 
data <- select(df,-Noise, -Intensity)

cor <- correlation::correlation(data)

cor |> 
  summary(redundant=TRUE) |> 
  cor_sort() |> 
  plot(show_text=FALSE) +
  ggtitle("Correlation Matrix of Complexity Indices") +
  theme(axis.text.x = element_text(angle=45, hjust = 1))
```

### Hierarchical CLustering


```{r message=FALSE, warning=FALSE}
rez <- parameters::cluster_analysis(as.data.frame(t(data)), n=4, method="hclust", hclust_method="ward.D2")
# plot(rez)

attributes(rez)$model |> 
  plot(hang = -1)
```


## References
